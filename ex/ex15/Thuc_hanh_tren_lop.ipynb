{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgz7PRMZp_-F"
      },
      "source": [
        "# Thực hành Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qzUdsI-p_-G"
      },
      "source": [
        "Trong bài này, ta sẽ thực hành cài đặt Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-WIxa1Ip_-H"
      },
      "source": [
        "### 1. Cài đặt và import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WdMvH4x9swj",
        "outputId": "e658418c-fc60-4482-ff57-adc0a378c79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "!which python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WeaDuInvI8WM",
        "outputId": "e0d1352d-af94-4c76-f9d7-e93be1a9e805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.0 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch\n",
        "!pip install torch==2.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I4ObXVBqjGby",
        "outputId": "186701e3-b8f0-4f69-fe89-89ad6cbcf7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18.0) (12.6.85)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18.0) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install spacy dill\n",
        "!pip3 install torchtext==0.18.0\n",
        "!pip3 install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "US4j_5D69swl"
      },
      "outputs": [],
      "source": [
        "# !python3 -m spacy download en && python3 -m spacy download fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqnH5eWcb_7M",
        "outputId": "5ce86c89-e40d-413a-b339-a49d39844090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download en_core_web_sm\n",
        "!python3 -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OaNedrhUjGb0"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchtext\n",
        "import copy\n",
        "import math\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I6462QxLjGb0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDAmgVPvp_-K"
      },
      "source": [
        "### 2. Cài đặt từng module của Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DosoYt1YjGb0"
      },
      "outputs": [],
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, dim):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBaPrBG0ubI-"
      },
      "source": [
        "**Position Embedding Class**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MJs0_6GwjGb1"
      },
      "outputs": [],
      "source": [
        "# Positional encoding\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, dim, max_seq_len=300):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "        # create a constant 'pe' matrix with values dependant on\n",
        "        # pos and i\n",
        "        pe = torch.zeros(max_seq_len, dim)\n",
        "\n",
        "        ########################\n",
        "        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, dim, 2).float() * -(math.log(10000.0) / dim))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        ########################\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make embeddings relatively larger\n",
        "        x = x *math.sqrt(self.dim)\n",
        "        # add constant to embedding\n",
        "        seq_len = x.size(1)\n",
        "        # x = x + Variable(self.pe[:, :seq_len], requires_grad=False).to(device)\n",
        "        x = x + self.pe[:, :seq_len].to(device)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F25tcm9tu1ce"
      },
      "source": [
        "**Multi Head Attention**: We first start with implementing attention function\n",
        "\n",
        "Attention of $q$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wJEKoan4jGb2"
      },
      "outputs": [],
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        if mask.dim() == 3:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "\n",
        "    output = torch.matmul(scores, v)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4vvVcNXBjGb1"
      },
      "outputs": [],
      "source": [
        "# Multi-headed attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.dim_head = dim//heads\n",
        "        self.h = heads\n",
        "        self.q_linear = nn.Linear(dim, dim)\n",
        "        self.k_linear = nn.Linear(dim, dim)\n",
        "        self.v_linear = nn.Linear(dim, dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        bs = q.size(0)\n",
        "        # perform linear operation and split into h heads\n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.dim_head)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.dim_head)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.dim_head)\n",
        "        # transpose to get dimensions bs * h * sl * dim\n",
        "        k = k.transpose(1, 2)\n",
        "        q = q.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "        # calculate attention using the function we will define next\n",
        "        # scores = attention(q, k, v, self.dim, mask, self.dropout)\n",
        "        scores = attention(q, k, v, self.dim_head, mask, self.dropout)\n",
        "        # concatenate heads and put through final linear layer\n",
        "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.dim)\n",
        "        output = self.out(concat)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2Cy0Xt9QjGb2"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        # We set d_ff as a default to 2048\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v7UTrblYjGb2"
      },
      "outputs": [],
      "source": [
        "class Norm(nn.Module):\n",
        "    def __init__(self, d_model, eps = 1e-6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.size = d_model\n",
        "        # create two learnable parameters to calibrate normalisation\n",
        "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "        self.eps = eps\n",
        "    def forward(self, x):\n",
        "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
        "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "        return norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1uYXmKKsjGb2"
      },
      "outputs": [],
      "source": [
        "# build an encoder layer with one multi-head attention layer and one\n",
        "# feed-forward layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.attn = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        ########################\n",
        "        x2 = self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn(x2, x2, x2, mask))\n",
        "\n",
        "        x2 = self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.ff(x2))\n",
        "        return x\n",
        "        ########################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8AWL51G_jGb3"
      },
      "outputs": [],
      "source": [
        "# build a decoder layer with two multi-head attention layers and\n",
        "# one feed-forward layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.norm_3 = Norm(d_model)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model).cuda()\n",
        "\n",
        "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
        "        ########################\n",
        "        x2 = self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
        "\n",
        "        x2 = self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
        "\n",
        "        x2 = self.norm_3(x)\n",
        "        x = x + self.dropout_3(self.ff(x2))\n",
        "        return x\n",
        "        ########################\n",
        "\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mQAOcVwqjGb3"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "        self.norm = Norm(d_model)\n",
        "\n",
        "    def forward(self, src, mask):\n",
        "        ########################\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, mask)\n",
        "        return self.norm(x)\n",
        "        ########################\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "        self.norm = Norm(d_model)\n",
        "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "        ########################\n",
        "        x = self.embed(trg)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
        "        return self.norm(x)\n",
        "        ########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TtVVMjazjGb3"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        e_outputs = self.encoder(src, src_mask)\n",
        "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
        "        output = self.out(d_output)\n",
        "        return output# we don't perform softmax on the output as this will be handled\n",
        "# automatically by our loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEINBKX-p_-N"
      },
      "source": [
        "### 3. Chuẩn bị và tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZY3841jbjGb4"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "\n",
        "# Tokenize\n",
        "\n",
        "class tokenize(object):\n",
        "\n",
        "    def __init__(self, lang):\n",
        "        self.nlp = spacy.load(lang)\n",
        "\n",
        "    def tokenizer(self, sentence):\n",
        "        sentence = re.sub(\n",
        "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
        "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
        "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
        "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
        "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
        "        sentence = sentence.lower()\n",
        "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xLDB_d_mjGb4"
      },
      "outputs": [],
      "source": [
        "# # Creating batch\n",
        "# from torchtext.legacy import data\n",
        "# import numpy as np\n",
        "# from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# def nopeak_mask(size, opt):\n",
        "#     np_mask = np.triu(np.ones((1, size, size)),\n",
        "#     k=1).astype('uint8')\n",
        "#     np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
        "#     np_mask = np_mask.to(device)\n",
        "#     return np_mask\n",
        "\n",
        "# def create_masks(src, trg, opt):\n",
        "\n",
        "#     src_mask = (src != opt.src_pad).unsqueeze(-2)\n",
        "\n",
        "#     if trg is not None:\n",
        "#         trg.to(device)\n",
        "#         trg_mask = (trg != opt.trg_pad).unsqueeze(-2).to(device)\n",
        "#         size = trg.size(1) # get seq_len for matrix\n",
        "#         np_mask = nopeak_mask(size, opt)\n",
        "#         trg_mask = trg_mask & np_mask\n",
        "\n",
        "#     else:\n",
        "#         trg_mask = None\n",
        "#     return src_mask, trg_mask\n",
        "\n",
        "# # patch on Torchtext's batching process that makes it more efficient\n",
        "# # from http://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks\n",
        "\n",
        "# class MyIterator(data.Iterator):\n",
        "#     def create_batches(self):\n",
        "#         if self.train:\n",
        "#             def pool(d, random_shuffler):\n",
        "#                 for p in data.batch(d, self.batch_size * 100):\n",
        "#                     p_batch = data.batch(\n",
        "#                         sorted(p, key=self.sort_key),\n",
        "#                         self.batch_size, self.batch_size_fn)\n",
        "#                     for b in random_shuffler(list(p_batch)):\n",
        "#                         yield b\n",
        "#             self.batches = pool(self.data(), self.random_shuffler)\n",
        "\n",
        "#         else:\n",
        "#             self.batches = []\n",
        "#             for b in data.batch(self.data(), self.batch_size,\n",
        "#                                           self.batch_size_fn):\n",
        "#                 self.batches.append(sorted(b, key=self.sort_key))\n",
        "\n",
        "# global max_src_in_batch, max_tgt_in_batch\n",
        "\n",
        "# def batch_size_fn(new, count, sofar):\n",
        "#     \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "#     global max_src_in_batch, max_tgt_in_batch\n",
        "#     if count == 1:\n",
        "#         max_src_in_batch = 0\n",
        "#         max_tgt_in_batch = 0\n",
        "#     max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
        "#     max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
        "#     src_elements = count * max_src_in_batch\n",
        "#     tgt_elements = count * max_tgt_in_batch\n",
        "#     return max(src_elements, tgt_elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0q1zaWS0Yl",
        "outputId": "dd625c0b-2dc9-41b8-ffaa-f0605b599da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "# === Modernized cell 1: masks + utilities ===\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import spacy\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def nopeak_mask(size, device=device):\n",
        "    \"\"\"\n",
        "    Returns a mask for preventing attention to future tokens.\n",
        "    Shape expected by downstream: (1, size, size) (broadcastable)\n",
        "    \"\"\"\n",
        "    # upper triangular with 1s above diagonal\n",
        "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
        "    mask = torch.from_numpy(np_mask) == 0  # True where allowed\n",
        "    return mask.to(device)\n",
        "\n",
        "def create_masks(src, trg, src_pad, trg_pad, device=device):\n",
        "    \"\"\"\n",
        "    src: LongTensor shape (batch, src_len)\n",
        "    trg: LongTensor shape (batch, trg_len)  OR None for inference\n",
        "    Returns: src_mask (batch,1,src_len), trg_mask (batch,1,trg_len, trg_len) or None\n",
        "    \"\"\"\n",
        "    # src_mask: (batch, 1, src_len)\n",
        "    src_mask = (src != src_pad).unsqueeze(1).to(device)\n",
        "\n",
        "    if trg is not None:\n",
        "        # trg_mask: (batch, 1, trg_len)\n",
        "        trg_mask = (trg != trg_pad).unsqueeze(1).to(device)  # (batch,1,trg_len)\n",
        "        seq_len = trg.size(1)\n",
        "        np_mask = nopeak_mask(seq_len, device)  # (1, seq_len, seq_len)\n",
        "        # combine padding mask and subsequent mask\n",
        "        # Need to broadcast trg_mask to (batch, seq_len) -> (batch, 1, seq_len) & np_mask (1, seq_len, seq_len)\n",
        "        # final shape: (batch, seq_len, seq_len) after broadcasting; some models expect (batch, 1, seq_len, seq_len) - adapt as needed\n",
        "        trg_mask = trg_mask & np_mask  # broadcasting: (batch,1,seq_len) & (1,seq_len,seq_len) -> (batch, seq_len, seq_len) because of alignment\n",
        "        # For compatibility with many implementations, return shape (batch, 1, seq_len, seq_len)\n",
        "        trg_mask = trg_mask.unsqueeze(1)  # (batch,1,seq_len,seq_len)\n",
        "    else:\n",
        "        trg_mask = None\n",
        "\n",
        "    return src_mask, trg_mask\n",
        "\n",
        "# === Batch-sizing helper retained (optional) ===\n",
        "# If you want dynamic batching by tokens (like original), you can keep this function and use it when creating batches.\n",
        "global max_src_in_batch, max_tgt_in_batch\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new['src']))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new['trg']) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T0jx8nh0jGb5"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import torchtext\n",
        "# from torchtext.legacy import data\n",
        "# import os\n",
        "# import dill as pickle\n",
        "\n",
        "# def read_data(opt):\n",
        "#     if opt.src_data is not None:\n",
        "#         try:\n",
        "#             opt.src_data = open(opt.src_data).read().strip().split('\\n')\n",
        "#         except:\n",
        "#             print(\"error: '\" + opt.src_data + \"' file not found\")\n",
        "#             quit()\n",
        "\n",
        "#     if opt.trg_data is not None:\n",
        "#         try:\n",
        "#             opt.trg_data = open(opt.trg_data).read().strip().split('\\n')\n",
        "#         except:\n",
        "#             print(\"error: '\" + opt.trg_data + \"' file not found\")\n",
        "#             quit()\n",
        "\n",
        "# def create_fields(opt):\n",
        "#     spacy_langs = ['en', 'fr', 'de', 'es', 'pt', 'it', 'nl']\n",
        "#     src_lang = opt.src_lang[0:2]\n",
        "#     trg_lang = opt.trg_lang[0:2]\n",
        "#     if src_lang not in spacy_langs:\n",
        "#         print('invalid src language: ' + opt.src_lang + 'supported languages : ' + spacy_langs)\n",
        "#     if trg_lang not in spacy_langs:\n",
        "#         print('invalid trg language: ' + opt.trg_lang + 'supported languages : ' + spacy_langs)\n",
        "\n",
        "#     print(\"loading spacy tokenizers...\")\n",
        "\n",
        "#     t_src = tokenize(opt.src_lang)\n",
        "#     t_trg = tokenize(opt.trg_lang)\n",
        "#     TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n",
        "#     SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n",
        "\n",
        "#     return(SRC, TRG)\n",
        "\n",
        "# def create_dataset(opt, SRC, TRG):\n",
        "\n",
        "#     print(\"creating dataset and iterator... \")\n",
        "\n",
        "#     raw_data = {'src' : [line for line in opt.src_data], 'trg': [line for line in opt.trg_data]}\n",
        "#     df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n",
        "\n",
        "#     mask = (df['src'].str.count(' ') < opt.max_strlen) & (df['trg'].str.count(' ') < opt.max_strlen)\n",
        "#     df = df.loc[mask]\n",
        "\n",
        "#     df.to_csv(\"translate_transformer_temp.csv\", index=False)\n",
        "\n",
        "#     data_fields = [('src', SRC), ('trg', TRG)]\n",
        "#     train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
        "\n",
        "#     train_iter = MyIterator(train, batch_size=opt.batchsize, device=device,\n",
        "#                         repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "#                         batch_size_fn=batch_size_fn, train=True, shuffle=True)\n",
        "\n",
        "#     os.remove('translate_transformer_temp.csv')\n",
        "#     SRC.build_vocab(train)\n",
        "#     TRG.build_vocab(train)\n",
        "#     opt.src_pad = SRC.vocab.stoi['<pad>']\n",
        "#     opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
        "\n",
        "#     opt.train_len = get_len(train_iter)\n",
        "\n",
        "#     return train_iter\n",
        "\n",
        "# def get_len(train):\n",
        "\n",
        "#     for i, b in enumerate(train):\n",
        "#         pass\n",
        "\n",
        "#     return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VWx9Y4H1S95H"
      },
      "outputs": [],
      "source": [
        "# === Modernized cell 2: dataset, vocab, iterator (DataLoader + collate_fn) ===\n",
        "import os\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "\n",
        "# Simple wrapper to get spacy tokenizer\n",
        "def get_spacy_tokenizer(lang_code):\n",
        "    # lang_code e.g., 'en_core_web_sm' or 'en'\n",
        "    # Accept either 'en' or 'en_core_web_sm' in opt.src_lang\n",
        "    name = lang_code if '_' in lang_code else f\"{lang_code}_core_web_sm\"\n",
        "    try:\n",
        "        nlp = spacy.load(name)\n",
        "    except Exception as e:\n",
        "        # user may need to install the model\n",
        "        raise RuntimeError(f\"Spacy model '{name}' not found. Install with: python -m spacy download {name}\") from e\n",
        "\n",
        "    def tokenize_text(text):\n",
        "        return [tok.text.lower() for tok in nlp(text)]\n",
        "    return tokenize_text\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_lines, trg_lines, src_tok_fn, trg_tok_fn, src_vocab, trg_vocab, add_sos_eos=True):\n",
        "        assert len(src_lines) == len(trg_lines)\n",
        "        self.src_lines = src_lines\n",
        "        self.trg_lines = trg_lines\n",
        "        self.src_tok_fn = src_tok_fn\n",
        "        self.trg_tok_fn = trg_tok_fn\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.add_sos_eos = add_sos_eos\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_lines)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.src_lines[idx]\n",
        "        trg_text = self.trg_lines[idx]\n",
        "        src_tokens = self.src_tok_fn(src_text)\n",
        "        trg_tokens = self.trg_tok_fn(trg_text)\n",
        "        if self.add_sos_eos:\n",
        "            trg_tokens = ['<sos>'] + trg_tokens + ['<eos>']\n",
        "        # numericalize lazily in collate\n",
        "        return {'src': src_tokens, 'trg': trg_tokens}\n",
        "\n",
        "def yield_tokens(lines, tokenizer):\n",
        "    for line in lines:\n",
        "        yield tokenizer(line)\n",
        "\n",
        "def build_vocabs(opt, src_lines, trg_lines, src_tok_fn, trg_tok_fn, min_freq=2):\n",
        "    specials = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
        "    src_vocab = build_vocab_from_iterator(yield_tokens(src_lines, src_tok_fn),\n",
        "                                         specials=specials,\n",
        "                                         special_first=True)\n",
        "    trg_vocab = build_vocab_from_iterator(yield_tokens(trg_lines, trg_tok_fn),\n",
        "                                         specials=specials,\n",
        "                                         special_first=True)\n",
        "\n",
        "    # set default index for unknown tokens\n",
        "    src_vocab.set_default_index(src_vocab['<unk>'])\n",
        "    trg_vocab.set_default_index(trg_vocab['<unk>'])\n",
        "    return src_vocab, trg_vocab\n",
        "\n",
        "def numericalize(tokens_list, vocab):\n",
        "    return [vocab[token] for token in tokens_list]\n",
        "\n",
        "def collate_fn(batch, src_vocab, trg_vocab, max_strlen=None, device=device):\n",
        "    # batch is a list of {'src': [...tokens...], 'trg': [...tokens...]}\n",
        "    src_batch = [torch.tensor(numericalize(x['src'], src_vocab), dtype=torch.long) for x in batch]\n",
        "    trg_batch = [torch.tensor(numericalize(x['trg'], trg_vocab), dtype=torch.long) for x in batch]\n",
        "\n",
        "    # optionally filter by max length (similar to your mask earlier)\n",
        "    if max_strlen is not None:\n",
        "        keep_indices = [i for i, (s, t) in enumerate(zip(src_batch, trg_batch))\n",
        "                        if s.size(0) <= max_strlen and t.size(0) <= max_strlen]\n",
        "        if len(keep_indices) != len(batch):\n",
        "            src_batch = [src_batch[i] for i in keep_indices]\n",
        "            trg_batch = [trg_batch[i] for i in keep_indices]\n",
        "\n",
        "    # pad sequences to longest in batch (pad value is index of '<pad>')\n",
        "    pad_idx_src = src_vocab['<pad>']\n",
        "    pad_idx_trg = trg_vocab['<pad>']\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=pad_idx_src).to(device)  # (batch, src_len)\n",
        "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=pad_idx_trg).to(device)  # (batch, trg_len)\n",
        "\n",
        "    return src_padded, trg_padded\n",
        "\n",
        "def read_data(opt):\n",
        "    \"\"\"Read text files into lists of lines (keeps your original API)\"\"\"\n",
        "    if opt.src_data is not None:\n",
        "        try:\n",
        "            opt.src_data = open(opt.src_data).read().strip().split('\\n')\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"error: '{opt.src_data}' file not found\") from e\n",
        "\n",
        "    if opt.trg_data is not None:\n",
        "        try:\n",
        "            opt.trg_data = open(opt.trg_data).read().strip().split('\\n')\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"error: '{opt.trg_data}' file not found\") from e\n",
        "\n",
        "def create_dataset_and_dataloader(opt, device=device):\n",
        "    \"\"\"\n",
        "    Replaces your create_fields + create_dataset workflow.\n",
        "    Returns: dataloader, src_vocab, trg_vocab, pad indices, dataset length\n",
        "    \"\"\"\n",
        "    print(\"Creating tokenizers...\")\n",
        "    src_lang = opt.src_lang #[0:2]\n",
        "    trg_lang = opt.trg_lang#[0:2]\n",
        "    src_tok = get_spacy_tokenizer(src_lang)\n",
        "    trg_tok = get_spacy_tokenizer(trg_lang)\n",
        "\n",
        "    # We expect opt.src_data and opt.trg_data to be lists of lines (read_data should be called first)\n",
        "    src_lines = opt.src_data\n",
        "    trg_lines = opt.trg_data\n",
        "\n",
        "    print(\"Building vocabs...\")\n",
        "    src_vocab, trg_vocab = build_vocabs(opt, src_lines, trg_lines, src_tok, trg_tok)\n",
        "\n",
        "    print(\"Creating dataset...\")\n",
        "    dataset = TranslationDataset(src_lines, trg_lines, src_tok, trg_tok, src_vocab, trg_vocab, add_sos_eos=True)\n",
        "\n",
        "    # create DataLoader with custom collate that closes over vocabs and max_strlen\n",
        "    my_collate = partial(collate_fn, src_vocab=src_vocab, trg_vocab=trg_vocab, max_strlen=getattr(opt, 'max_strlen', None))\n",
        "    dataloader = DataLoader(dataset, batch_size=opt.batchsize, shuffle=True, collate_fn=my_collate)\n",
        "\n",
        "    # pad ids\n",
        "    opt.src_pad = src_vocab['<pad>']\n",
        "    opt.trg_pad = trg_vocab['<pad>']\n",
        "\n",
        "    # compute train_len like original get_len (number of batches)\n",
        "    train_len = len(dataloader)\n",
        "\n",
        "    return dataloader, src_vocab, trg_vocab, opt.src_pad, opt.trg_pad, train_len\n",
        "\n",
        "# Example helper to iterate get_len as before (if you want compatibility)\n",
        "def get_len(dataloader):\n",
        "    for i, b in enumerate(dataloader):\n",
        "        pass\n",
        "    return i\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0BQE7Jap_-O"
      },
      "source": [
        "### 4. Cài đặt giải thuật tối ưu và huấn luyện mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hvXmikJB9swr"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "class CosineWithRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
        "    \"\"\"\n",
        "    Cosine annealing with restarts.\n",
        "    Parameters\n",
        "    ----------\n",
        "    optimizer : torch.optim.Optimizer\n",
        "    T_max : int\n",
        "        The maximum number of iterations within the first cycle.\n",
        "    eta_min : float, optional (default: 0)\n",
        "        The minimum learning rate.\n",
        "    last_epoch : int, optional (default: -1)\n",
        "        The index of the last epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 T_max: int,\n",
        "                 eta_min: float = 0.,\n",
        "                 last_epoch: int = -1,\n",
        "                 factor: float = 1.) -> None:\n",
        "        # pylint: disable=invalid-name\n",
        "        self.T_max = T_max\n",
        "        self.eta_min = eta_min\n",
        "        self.factor = factor\n",
        "        self._last_restart: int = 0\n",
        "        self._cycle_counter: int = 0\n",
        "        self._cycle_factor: float = 1.\n",
        "        self._updated_cycle_len: int = T_max\n",
        "        self._initialized: bool = False\n",
        "        super(CosineWithRestarts, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"Get updated learning rate.\"\"\"\n",
        "        # HACK: We need to check if this is the first time get_lr() was called, since\n",
        "        # we want to start with step = 0, but _LRScheduler calls get_lr with\n",
        "        # last_epoch + 1 when initialized.\n",
        "        if not self._initialized:\n",
        "            self._initialized = True\n",
        "            return self.base_lrs\n",
        "\n",
        "        step = self.last_epoch + 1\n",
        "        self._cycle_counter = step - self._last_restart\n",
        "\n",
        "        lrs = [\n",
        "            (\n",
        "                self.eta_min + ((lr - self.eta_min) / 2) *\n",
        "                (\n",
        "                    np.cos(\n",
        "                        np.pi *\n",
        "                        ((self._cycle_counter) % self._updated_cycle_len) /\n",
        "                        self._updated_cycle_len\n",
        "                    ) + 1\n",
        "                )\n",
        "            ) for lr in self.base_lrs\n",
        "        ]\n",
        "\n",
        "        if self._cycle_counter % self._updated_cycle_len == 0:\n",
        "            # Adjust the cycle length.\n",
        "            self._cycle_factor *= self.factor\n",
        "            self._cycle_counter = 0\n",
        "            self._updated_cycle_len = int(self._cycle_factor * self.T_max)\n",
        "            self._last_restart = step\n",
        "\n",
        "        return lrs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TRTtm5kO9swr",
        "outputId": "64f3c6b9-6e3c-4733-bb24-01e80b81fdfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-24 14:14:47--  https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/english.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4897403 (4.7M) [text/plain]\n",
            "Saving to: ‘english.txt’\n",
            "\n",
            "english.txt         100%[===================>]   4.67M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-10-24 14:14:47 (69.0 MB/s) - ‘english.txt’ saved [4897403/4897403]\n",
            "\n",
            "--2025-10-24 14:14:47--  https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/french.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5938378 (5.7M) [text/plain]\n",
            "Saving to: ‘french.txt’\n",
            "\n",
            "french.txt          100%[===================>]   5.66M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-10-24 14:14:48 (97.6 MB/s) - ‘french.txt’ saved [5938378/5938378]\n",
            "\n",
            "--2025-10-24 14:14:48--  http://data/french.txt\n",
            "Resolving data (data)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘data’\n",
            "FINISHED --2025-10-24 14:14:48--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 1 files, 5.7M in 0.06s (97.6 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/english.txt\n",
        "!mv english.txt data\n",
        "!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/french.txt data/french.txt\n",
        "!mv french.txt data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LSOX2OEW9swr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model(opt, src_vocab, trg_vocab):\n",
        "\n",
        "    assert opt.d_model % opt.heads == 0\n",
        "    assert opt.dropout < 1\n",
        "\n",
        "    model = Transformer(src_vocab, trg_vocab, opt.d_model, opt.n_layers, opt.heads)\n",
        "\n",
        "    if opt.load_weights is not None:\n",
        "        print(\"loading pretrained weights...\")\n",
        "        model.load_state_dict(torch.load(f'{opt.load_weights}/model_weights'))\n",
        "    else:\n",
        "        for p in model.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    if opt.device == 0:\n",
        "        model = model.cuda()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q2qOSP7jGb5",
        "outputId": "cb3bdb4b-7846-4c3d-fe46-ebc31bc8edba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating tokenizers...\n",
            "Building vocabs...\n",
            "Creating dataset...\n",
            "Train steps per epoch: 4841\n",
            "Epoch [1/2], Step [100/4841], Loss: 7.0322, Time: 44.35s\n",
            "Epoch [1/2], Step [200/4841], Loss: 5.2132, Time: 42.56s\n",
            "Epoch [1/2], Step [300/4841], Loss: 4.7141, Time: 43.99s\n",
            "Epoch [1/2], Step [400/4841], Loss: 4.4322, Time: 43.76s\n",
            "Epoch [1/2], Step [500/4841], Loss: 4.2238, Time: 42.98s\n",
            "Epoch [1/2], Step [600/4841], Loss: 4.0578, Time: 44.35s\n",
            "Epoch [1/2], Step [700/4841], Loss: 3.9467, Time: 43.34s\n",
            "Epoch [1/2], Step [800/4841], Loss: 3.7916, Time: 43.95s\n",
            "Epoch [1/2], Step [900/4841], Loss: 3.6988, Time: 43.90s\n",
            "Epoch [1/2], Step [1000/4841], Loss: 3.5549, Time: 43.12s\n",
            "Epoch [1/2], Step [1100/4841], Loss: 3.4962, Time: 43.78s\n",
            "Epoch [1/2], Step [1200/4841], Loss: 3.3923, Time: 43.26s\n",
            "Epoch [1/2], Step [1300/4841], Loss: 3.3500, Time: 44.35s\n",
            "Epoch [1/2], Step [1400/4841], Loss: 3.2424, Time: 43.92s\n",
            "Epoch [1/2], Step [1500/4841], Loss: 3.2019, Time: 43.54s\n",
            "Epoch [1/2], Step [1600/4841], Loss: 3.0981, Time: 44.04s\n",
            "Epoch [1/2], Step [1700/4841], Loss: 3.0205, Time: 43.14s\n",
            "Epoch [1/2], Step [1800/4841], Loss: 3.0208, Time: 44.30s\n",
            "Epoch [1/2], Step [1900/4841], Loss: 2.9652, Time: 43.78s\n",
            "Epoch [1/2], Step [2000/4841], Loss: 2.8913, Time: 43.20s\n",
            "Epoch [1/2], Step [2100/4841], Loss: 2.8532, Time: 43.80s\n",
            "Epoch [1/2], Step [2200/4841], Loss: 2.7772, Time: 42.99s\n",
            "Epoch [1/2], Step [2300/4841], Loss: 2.7598, Time: 43.88s\n",
            "Epoch [1/2], Step [2400/4841], Loss: 2.7203, Time: 43.65s\n",
            "Epoch [1/2], Step [2500/4841], Loss: 2.6942, Time: 44.07s\n",
            "Epoch [1/2], Step [2600/4841], Loss: 2.6318, Time: 44.15s\n",
            "Epoch [1/2], Step [2700/4841], Loss: 2.5789, Time: 44.00s\n",
            "Epoch [1/2], Step [2800/4841], Loss: 2.5298, Time: 44.49s\n",
            "Epoch [1/2], Step [2900/4841], Loss: 2.5108, Time: 44.22s\n",
            "Epoch [1/2], Step [3000/4841], Loss: 2.5147, Time: 43.70s\n",
            "Epoch [1/2], Step [3100/4841], Loss: 2.4330, Time: 43.77s\n",
            "Epoch [1/2], Step [3200/4841], Loss: 2.3908, Time: 43.33s\n",
            "Epoch [1/2], Step [3300/4841], Loss: 2.3942, Time: 44.08s\n",
            "Epoch [1/2], Step [3400/4841], Loss: 2.3650, Time: 43.90s\n",
            "Epoch [1/2], Step [3500/4841], Loss: 2.3383, Time: 43.95s\n",
            "Epoch [1/2], Step [3600/4841], Loss: 2.3035, Time: 44.47s\n",
            "Epoch [1/2], Step [3700/4841], Loss: 2.3173, Time: 43.70s\n",
            "Epoch [1/2], Step [3800/4841], Loss: 2.2443, Time: 43.78s\n",
            "Epoch [1/2], Step [3900/4841], Loss: 2.1984, Time: 43.94s\n",
            "Epoch [1/2], Step [4000/4841], Loss: 2.2312, Time: 43.11s\n",
            "Epoch [1/2], Step [4100/4841], Loss: 2.1801, Time: 44.52s\n",
            "Epoch [1/2], Step [4200/4841], Loss: 2.2546, Time: 43.86s\n",
            "Epoch [1/2], Step [4300/4841], Loss: 2.1826, Time: 43.90s\n",
            "Epoch [1/2], Step [4400/4841], Loss: 2.1094, Time: 43.78s\n",
            "Epoch [1/2], Step [4500/4841], Loss: 2.1285, Time: 43.91s\n",
            "Epoch [1/2], Step [4600/4841], Loss: 2.1156, Time: 44.35s\n",
            "Epoch [1/2], Step [4700/4841], Loss: 2.1175, Time: 43.69s\n",
            "Epoch [1/2], Step [4800/4841], Loss: 2.0984, Time: 43.88s\n",
            "Epoch [2/2], Step [100/4841], Loss: 1.9797, Time: 61.25s\n",
            "Epoch [2/2], Step [200/4841], Loss: 1.9529, Time: 44.20s\n",
            "Epoch [2/2], Step [300/4841], Loss: 1.9356, Time: 42.84s\n",
            "Epoch [2/2], Step [400/4841], Loss: 1.9359, Time: 43.89s\n",
            "Epoch [2/2], Step [500/4841], Loss: 1.9320, Time: 43.19s\n",
            "Epoch [2/2], Step [600/4841], Loss: 1.9510, Time: 43.95s\n",
            "Epoch [2/2], Step [700/4841], Loss: 1.9401, Time: 43.68s\n",
            "Epoch [2/2], Step [800/4841], Loss: 1.9170, Time: 43.30s\n",
            "Epoch [2/2], Step [900/4841], Loss: 1.9586, Time: 43.96s\n",
            "Epoch [2/2], Step [1000/4841], Loss: 1.8728, Time: 43.34s\n",
            "Epoch [2/2], Step [1100/4841], Loss: 1.8490, Time: 44.13s\n",
            "Epoch [2/2], Step [1200/4841], Loss: 1.8803, Time: 43.45s\n",
            "Epoch [2/2], Step [1300/4841], Loss: 1.8848, Time: 44.04s\n",
            "Epoch [2/2], Step [1400/4841], Loss: 1.8521, Time: 44.41s\n",
            "Epoch [2/2], Step [1500/4841], Loss: 1.8516, Time: 42.79s\n",
            "Epoch [2/2], Step [1600/4841], Loss: 1.8784, Time: 44.00s\n",
            "Epoch [2/2], Step [1700/4841], Loss: 1.8381, Time: 43.32s\n",
            "Epoch [2/2], Step [1800/4841], Loss: 1.8153, Time: 43.59s\n",
            "Epoch [2/2], Step [1900/4841], Loss: 1.8140, Time: 43.54s\n",
            "Epoch [2/2], Step [2000/4841], Loss: 1.7905, Time: 43.39s\n",
            "Epoch [2/2], Step [2100/4841], Loss: 1.7963, Time: 43.61s\n",
            "Epoch [2/2], Step [2200/4841], Loss: 1.7967, Time: 43.21s\n",
            "Epoch [2/2], Step [2300/4841], Loss: 1.7560, Time: 43.93s\n",
            "Epoch [2/2], Step [2400/4841], Loss: 1.7535, Time: 43.28s\n",
            "Epoch [2/2], Step [2500/4841], Loss: 1.7333, Time: 43.42s\n",
            "Epoch [2/2], Step [2600/4841], Loss: 1.7564, Time: 43.28s\n",
            "Epoch [2/2], Step [2700/4841], Loss: 1.7474, Time: 43.42s\n",
            "Epoch [2/2], Step [2800/4841], Loss: 1.7422, Time: 44.43s\n",
            "Epoch [2/2], Step [2900/4841], Loss: 1.7595, Time: 42.68s\n",
            "Epoch [2/2], Step [3000/4841], Loss: 1.7585, Time: 43.32s\n",
            "Epoch [2/2], Step [3100/4841], Loss: 1.7250, Time: 43.24s\n",
            "Epoch [2/2], Step [3200/4841], Loss: 1.6917, Time: 43.55s\n",
            "Epoch [2/2], Step [3300/4841], Loss: 1.7216, Time: 42.99s\n",
            "Epoch [2/2], Step [3400/4841], Loss: 1.7400, Time: 43.87s\n",
            "Epoch [2/2], Step [3500/4841], Loss: 1.7315, Time: 42.90s\n",
            "Epoch [2/2], Step [3600/4841], Loss: 1.6453, Time: 46.81s\n",
            "Epoch [2/2], Step [3700/4841], Loss: 1.6875, Time: 43.89s\n",
            "Epoch [2/2], Step [3800/4841], Loss: 1.6964, Time: 43.35s\n",
            "Epoch [2/2], Step [3900/4841], Loss: 1.6842, Time: 43.52s\n",
            "Epoch [2/2], Step [4000/4841], Loss: 1.6504, Time: 44.46s\n",
            "Epoch [2/2], Step [4100/4841], Loss: 1.6688, Time: 42.92s\n",
            "Epoch [2/2], Step [4200/4841], Loss: 1.6633, Time: 43.56s\n",
            "Epoch [2/2], Step [4300/4841], Loss: 1.6844, Time: 43.38s\n",
            "Epoch [2/2], Step [4400/4841], Loss: 1.6266, Time: 43.64s\n",
            "Epoch [2/2], Step [4500/4841], Loss: 1.6521, Time: 43.29s\n",
            "Epoch [2/2], Step [4600/4841], Loss: 1.6534, Time: 44.17s\n",
            "Epoch [2/2], Step [4700/4841], Loss: 1.5828, Time: 44.45s\n",
            "Epoch [2/2], Step [4800/4841], Loss: 1.6355, Time: 43.28s\n",
            "training complete.\n"
          ]
        }
      ],
      "source": [
        "\"\"\" BAI TAP VE NHA \"\"\"\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "class Opt:\n",
        "    pass\n",
        "\n",
        "def train_model(model, dataloader, opt):\n",
        "    ########################\n",
        "\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "\n",
        "    # Định nghĩa criterion bên trong hàm\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=opt.trg_pad)\n",
        "\n",
        "    for epoch in range(opt.epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # 1. Lặp qua dataloader\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # 2. Lấy src, trg (đã là batch_first=True và trên device từ collate_fn)\n",
        "            src, trg = batch\n",
        "\n",
        "            # trg_input là <sos>...word (ví dụ: [1, 5, 7, 9])\n",
        "            trg_input = trg[:, :-1]\n",
        "            # trg_output là word...<eos> (ví dụ: [5, 7, 9, 2])\n",
        "            trg_output = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            # 3. Tạo mặt nạ (masks) với đúng tham số\n",
        "            src_mask, trg_mask = create_masks(src, trg_input, opt.src_pad, opt.trg_pad, opt.device)\n",
        "\n",
        "            opt.optimizer.zero_grad()\n",
        "\n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "\n",
        "            preds_flat = preds.contiguous().view(-1, preds.size(-1))\n",
        "\n",
        "            loss = criterion(preds_flat, trg_output)\n",
        "            loss.backward()\n",
        "\n",
        "            opt.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if (i + 1) % opt.printevery == 0:\n",
        "                avg_loss = total_loss / opt.printevery\n",
        "                print(f\"Epoch [{epoch+1}/{opt.epochs}], Step [{i+1}/{opt.train_len}], Loss: {avg_loss:.4f}, Time: {time.time() - start:.2f}s\")\n",
        "                total_loss = 0\n",
        "                start = time.time()\n",
        "\n",
        "        #checkpoint\n",
        "        if opt.checkpoint > 0:\n",
        "            print(f\"--- epoch {epoch+1} finished, saving weights ---\")\n",
        "            if not os.path.exists('weights'):\n",
        "                os.makedirs('weights')\n",
        "            torch.save(model.state_dict(), f'weights/model_epoch_{epoch+1}.weights')\n",
        "\n",
        "    print(\"training complete.\")\n",
        "    ########################\n",
        "\n",
        "\n",
        "def main():\n",
        "    opt = Opt()\n",
        "    opt.src_data = \"data/english.txt\"\n",
        "    opt.trg_data = \"data/french.txt\"\n",
        "    opt.src_lang = \"en_core_web_sm\"\n",
        "    opt.trg_lang = 'fr_core_news_sm'\n",
        "    opt.epochs = 2\n",
        "    opt.d_model=512\n",
        "    opt.n_layers=6\n",
        "    opt.heads=8\n",
        "    opt.dropout=0.1\n",
        "    opt.batchsize=32\n",
        "    opt.printevery=100\n",
        "    opt.lr=0.0001\n",
        "    opt.max_strlen=80\n",
        "    opt.checkpoint = 0\n",
        "    opt.no_cuda = False\n",
        "    opt.load_weights = None\n",
        "\n",
        "    # opt.device = 0\n",
        "    # if opt.device == 0:\n",
        "    #     assert torch.cuda.is_available()\n",
        "\n",
        "    # read_data(opt)\n",
        "    # SRC, TRG = create_fields(opt)\n",
        "    # opt.train = create_dataset(opt, SRC, TRG)\n",
        "    # model = get_model(opt, len(SRC.vocab), len(TRG.vocab)).to(device)\n",
        "\n",
        "    # opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    # if opt.checkpoint > 0:\n",
        "    #     print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
        "\n",
        "    # train_model(model, opt)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.no_cuda else \"cpu\")\n",
        "    opt.device = device\n",
        "\n",
        "    read_data(opt)\n",
        "\n",
        "    dataloader, src_vocab, trg_vocab, opt.src_pad, opt.trg_pad, opt.train_len = \\\n",
        "        create_dataset_and_dataloader(opt, device=device)\n",
        "\n",
        "    print(f\"Train steps per epoch: {opt.train_len}\")\n",
        "\n",
        "    model = get_model(opt, len(src_vocab), len(trg_vocab)).to(device)\n",
        "\n",
        "    opt.optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=opt.lr,\n",
        "        betas=(0.9, 0.98),\n",
        "        eps=1e-9\n",
        "    )\n",
        "\n",
        "    train_model(model, dataloader, opt)\n",
        "\n",
        "\n",
        "    # for asking about further training use while true loop, and return\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}